{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],

      "authorship_tag": "ABX9TyODlD1GX28XuLvoKkEORz21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PreyPython123/Master-V24-Semiveiledet-Regresjon/blob/Dataforst%C3%A5else-og-unders%C3%B8kelse-Pradeep/Bioco_Databehandling_av_manglende_verdier_og_utstikkere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"

      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasting av nødvendige pakker og bibliotek"
      ],
      "metadata": {
        "id": "GQBTgF29R_ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyod"
      ],
      "metadata": {
        "id": "-tRTZpwOSJjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40030387-2d46-496d-b55c-121135b07d0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyod in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyod) (1.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyod) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.23.5)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod) (0.41.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->pyod) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importering av nødvendige pakker og bibliotek"
      ],
      "metadata": {
        "id": "UnKseMxNSJ5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "from datetime import datetime\n",
        "\n",
        "from pyod.models.hbos import HBOS"
      ],
      "metadata": {
        "id": "z6VlWO7ESNWB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importering av data"
      ],
      "metadata": {
        "id": "IMnqlLDKSNpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Velger første kolonne med dato og tid som index\n",
        "bioco_data = pd.read_csv('/content/drive/MyDrive/MasterV24/Bioco_data/førbehandlet_bioco_data.csv',\n",
        "                         header=0,\n",
        "                         sep=',',\n",
        "                         index_col=0)\n",
        "\n",
        "# Formatterer index til riktig format og datatype\n",
        "bioco_data.index = pd.to_datetime(bioco_data.index,\n",
        "                                  format='%Y-%m-%d %H:%M:%S')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3okYBetzSRrr",
        "outputId": "d8e25120-dd7f-4111-a55b-1b7067a7cfc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oppdeling av data til prediktorer- og responsvariabler"
      ],
      "metadata": {
        "id": "KKG9d0VKJwry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasett for prediktorer\n",
        "prediktor_data = bioco_data.iloc[:, :-4]\n",
        "prediktorer = prediktor_data.columns\n",
        "\n",
        "# Verdier for prediktorer\n",
        "X = prediktor_data.values\n",
        "\n",
        "# Datasett for hver kvalitetsmåling\n",
        "collagen = bioco_data['Collagen']\n",
        "mw = bioco_data['Mw']\n",
        "smallmolecules = bioco_data['SmallMolecules']\n",
        "brixadjusted = bioco_data['BrixAdjusted']"
      ],
      "metadata": {
        "id": "Svt4JDn6KH2-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Behandling av manglende verdier"
      ],
      "metadata": {
        "id": "Tdq49s8wNRfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversikt over antall manglende verider for per kolonne"
      ],
      "metadata": {
        "id": "CWDz5G1g3sHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bioco_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9wbCE2c3yRE",
        "outputId": "721bf855-3cf2-4e57-ba82-37997b5f16d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EnzymeType_A1         0\n",
              "EnzymeType_A2         0\n",
              "EnzymeType_B          0\n",
              "EnzymeType_C          0\n",
              "EnzymeType_D          0\n",
              "EnzymeType_E          0\n",
              "RawMatFlow           55\n",
              "WaterFlow            55\n",
              "RawMatPercent        55\n",
              "NIRfat            14187\n",
              "NIRprotein        15731\n",
              "NIRash            13976\n",
              "NIRwater          13958\n",
              "TT07                 50\n",
              "TT08                 45\n",
              "PT03                 25\n",
              "TT20                 25\n",
              "TT09                 15\n",
              "TT12                  0\n",
              "Collagen          43152\n",
              "Mw                42711\n",
              "SmallMolecules    42711\n",
              "BrixAdjusted      42711\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversikt over rader med manglende verdier for RawMatflow"
      ],
      "metadata": {
        "id": "bKChyUmFNb4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Henter ut index til rader med manglende verdier for \"RawMatFlow\"\n",
        "rawmat_manglende_index = bioco_data[bioco_data['RawMatFlow'].isnull()].index\n",
        "\n",
        "# Sjekker hvilke andre kolonner som har manglende verdier for samme rader\n",
        "bioco_data[rawmat_manglende_index[0]:rawmat_manglende_index[-1]].isnull().sum()\n",
        "\n",
        "# Dropper de spesifikke rader fra datasett\n",
        "prosessert_data = bioco_data.drop(bioco_data.loc[rawmat_manglende_index[0]:rawmat_manglende_index[-1]].index)"
      ],
      "metadata": {
        "id": "n4tUgB555yNw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Behandling av manglende verdier for NIR målinger"
      ],
      "metadata": {
        "id": "pt20t9CbcPeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping av bestemte intervaller med manglende verdier"
      ],
      "metadata": {
        "id": "m_b6VbwJeJwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversikt over rader med manglende verdier for NIRfat"
      ],
      "metadata": {
        "id": "UHwRS04jEDsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Henter ut index til rader med manglende verdier for \"NIRfat\"\n",
        "nirfat_manglende_index = prosessert_data[prosessert_data['NIRfat'].isnull()].index\n",
        "\n",
        "# Lager liste for å lagre start og slutttid for serie med manglende verdier\n",
        "nirfat_manglende_index_start = list()\n",
        "nirfat_manglende_index_slutt = list()\n",
        "\n",
        "# Legger til starttid for første serie med manglende verdier\n",
        "nirfat_manglende_index_start.append(nirfat_manglende_index[0])\n",
        "\n",
        "# Lagrer alle start og slutttid for serier med manglende verdier\n",
        "for i in range(1, len(nirfat_manglende_index)):\n",
        "  tidsdiff = nirfat_manglende_index[i] - nirfat_manglende_index[i-1]\n",
        "\n",
        "  if tidsdiff.total_seconds() > 60:\n",
        "    nirfat_manglende_index_slutt.append(nirfat_manglende_index[i-1])\n",
        "    nirfat_manglende_index_start.append(nirfat_manglende_index[i])\n",
        "nirfat_manglende_index_slutt.append(nirfat_manglende_index[-1])\n",
        "\n",
        "# Maks grense på korte intervall for interpolering\n",
        "diff_max = 15\n",
        "\n",
        "# Lagring av antall manglende verider i korte intervaller\n",
        "res_nir_manglende_korteintervall = 0\n",
        "\n",
        "# Lager liste for start og slutt på korte intervaller med manglende verdier for NIRfat\n",
        "nirfat_manglende_maks15 = list()\n",
        "\n",
        "# Lager liste for start og slutt på lengre intervaller med manglende verdier for NIRfat\n",
        "nirfat_manglende_min15 = list()\n",
        "\n",
        "\n",
        "for i,j in zip(nirfat_manglende_index_start, nirfat_manglende_index_slutt):\n",
        "  nirfat_mangel = prosessert_data[i:j].isnull().sum()['NIRfat']\n",
        "\n",
        "# Lagrer alle start og sluttid for korte intervaller mindre enn maks tid\n",
        "  if nirfat_mangel <= diff_max:\n",
        "    nirfat_manglende_maks15.append((i,j))\n",
        "\n",
        "    # Summerer antall manglende verdier i de korte intertaller\n",
        "    res_nir_manglende_korteintervall += nirfat_mangel\n",
        "\n",
        "    # Sjekker om de korte intervaller inneholder kvalitetsmålinger\n",
        "    respons_mangel = prosessert_data[i:j].isnull().sum()[['Collagen',\n",
        "                                                          'Mw',\n",
        "                                                          'SmallMolecules',\n",
        "                                                          'BrixAdjusted']]\n",
        "    if nirfat_mangel > min(respons_mangel.values):\n",
        "      print(\"Tidsintervallet {} til {} har flere manglende NIRfat målinger enn kvalitetsmålinger\".format(i, j))\n",
        "      print(\"NIRfat {}\".format(nirfat_mangel))\n",
        "      print(respons_mangel)\n",
        "\n",
        "# Lagrer alle start og slutttid for lengre intervaller mer enn maks tid\n",
        "  else:\n",
        "    nirfat_manglende_min15.append((i,j))\n",
        "\n",
        "print(res_nir_manglende_korteintervall,\n",
        "      \"av\",\n",
        "      prosessert_data.isnull().sum()['NIRfat'],\n",
        "      \"NIRfat målinger som mangler er i kortere intervaller enn\",\n",
        "      diff_max,\n",
        "      \"min\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxPd09zMEIod",
        "outputId": "b8fd919f-dd06-4ed5-ad84-621d9d09bd79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132 av 14132 NIRfat målinger som mangler er i kortere intervaller enn 15 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropper de intervaller mer enn 15 min med manglende verdier for NIRfat"
      ],
      "metadata": {
        "id": "EqNIrkHzO_oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for start, end in nirfat_manglende_min15:\n",
        "    prosessert_data = prosessert_data[(prosessert_data.index < start) | (prosessert_data.index > end)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K19blvcPB34",
        "outputId": "b0cbf111-34f0-435c-fe5a-7da116aa54c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EnzymeType_A1         0\n",
              "EnzymeType_A2         0\n",
              "EnzymeType_B          0\n",
              "EnzymeType_C          0\n",
              "EnzymeType_D          0\n",
              "EnzymeType_E          0\n",
              "RawMatFlow            0\n",
              "WaterFlow             0\n",
              "RawMatPercent         0\n",
              "NIRfat              132\n",
              "NIRprotein         1676\n",
              "NIRash              178\n",
              "NIRwater            204\n",
              "TT07                  0\n",
              "TT08                  0\n",
              "PT03                  0\n",
              "TT20                  0\n",
              "TT09                  0\n",
              "TT12                  0\n",
              "Collagen          29107\n",
              "Mw                28736\n",
              "SmallMolecules    28736\n",
              "BrixAdjusted      28736\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversikt over manglende verdier for NIRwater"
      ],
      "metadata": {
        "id": "LxZxv8kCcJoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Henter ut index til rader med manglende verdier for \"NIRwater\"\n",
        "nirwater_manglende_index = prosessert_data[prosessert_data['NIRwater'].isnull()].index\n",
        "\n",
        "# Lager liste for å lagre start og slutttid for serie med manglende verdier\n",
        "nirwater_manglende_index_start = list()\n",
        "nirwater_manglende_index_slutt = list()\n",
        "\n",
        "# Legger til starttid for første serie med manglende verdier\n",
        "nirwater_manglende_index_start.append(nirwater_manglende_index[0])\n",
        "\n",
        "# Lagrer alle start og slutttid for serier med manglende verdier\n",
        "for i in range(1, len(nirwater_manglende_index)):\n",
        "  tidsdiff = nirwater_manglende_index[i] - nirwater_manglende_index[i-1]\n",
        "\n",
        "  if tidsdiff.total_seconds() > 60:\n",
        "    nirwater_manglende_index_slutt.append(nirwater_manglende_index[i-1])\n",
        "    nirwater_manglende_index_start.append(nirwater_manglende_index[i])\n",
        "nirwater_manglende_index_slutt.append(nirwater_manglende_index[-1])\n",
        "\n",
        "# Maks grense på korte intervall for interpolering\n",
        "diff_max = 15\n",
        "\n",
        "# Lagring av antall manglende verider i korte intervaller\n",
        "res_water_manglende_korteintervall = 0\n",
        "\n",
        "# Lager liste for start og slutt på korte intervaller med manglende verdier for NIRwater\n",
        "nirwater_manglende_maks15 = list()\n",
        "\n",
        "# Lager liste for start og slutt på lengre intervaller med manglende verdier for NIRwater\n",
        "nirwater_manglende_min15 = list()\n",
        "\n",
        "\n",
        "for i,j in zip(nirwater_manglende_index_start, nirwater_manglende_index_slutt):\n",
        "  nirwater_mangel = prosessert_data[i:j].isnull().sum()['NIRwater']\n",
        "\n",
        "# Lagrer alle start og sluttid for korte intervaller mindre enn maks tid\n",
        "  if nirwater_mangel <= diff_max:\n",
        "    nirwater_manglende_maks15.append((i,j))\n",
        "\n",
        "    # Summerer antall manglende verdier i de korte intertaller\n",
        "    res_water_manglende_korteintervall += nirwater_mangel\n",
        "\n",
        "    # Sjekker om de korte intervaller inneholder kvalitetsmålinger\n",
        "    respons_mangel = prosessert_data[i:j].isnull().sum()[['Collagen',\n",
        "                                                          'Mw',\n",
        "                                                          'SmallMolecules',\n",
        "                                                          'BrixAdjusted']]\n",
        "    if nirwater_mangel > min(respons_mangel.values):\n",
        "      print(\"Tidsintervallet {} til {} har flere manglende NIRwater målinger enn kvalitetsmålinger\".format(i, j))\n",
        "      print(\"NIRwater {}\".format(nirwater_mangel))\n",
        "      print(respons_mangel)\n",
        "\n",
        "# Lagrer alle start og slutttid for lengre intervaller mer enn maks tid\n",
        "  else:\n",
        "    nirwater_manglende_min15.append((i,j))\n",
        "\n",
        "print(res_water_manglende_korteintervall,\n",
        "      \"av\",\n",
        "      prosessert_data.isnull().sum()['NIRwater'],\n",
        "      \"NIRwater målinger som mangler er i kortere intervaller enn\",\n",
        "      diff_max,\n",
        "      \"min\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF2_NrB-ZXSs",
        "outputId": "d1210f7b-8508-4815-c800-221567ab583c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144 av 204 NIRwater målinger som mangler er i kortere intervaller enn 15 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropper de intervaller mer enn 15 min med manglende verdier for NIRwater"
      ],
      "metadata": {
        "id": "SzyoN9nibmuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for start, end in nirwater_manglende_min15:\n",
        "    prosessert_data = prosessert_data[(prosessert_data.index < start) | (prosessert_data.index > end)]"
      ],
      "metadata": {
        "id": "7uhvK5JUbnQc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversikt over manglende verdier for NIRash"
      ],
      "metadata": {
        "id": "ZmJtHYaQb-s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Henter ut index til rader med manglende verdier for \"NIRash\"\n",
        "nirash_manglende_index = prosessert_data[prosessert_data['NIRash'].isnull()].index\n",
        "\n",
        "# Lager liste for å lagre start og slutttid for serie med manglende verdier\n",
        "nirash_manglende_index_start = list()\n",
        "nirash_manglende_index_slutt = list()\n",
        "\n",
        "# Legger til starttid for første serie med manglende verdier\n",
        "nirash_manglende_index_start.append(nirash_manglende_index[0])\n",
        "\n",
        "# Lagrer alle start og slutttid for serier med manglende verdier\n",
        "for i in range(1, len(nirash_manglende_index)):\n",
        "  tidsdiff = nirash_manglende_index[i] - nirash_manglende_index[i-1]\n",
        "\n",
        "  if tidsdiff.total_seconds() > 60:\n",
        "    nirash_manglende_index_slutt.append(nirash_manglende_index[i-1])\n",
        "    nirash_manglende_index_start.append(nirash_manglende_index[i])\n",
        "nirash_manglende_index_slutt.append(nirash_manglende_index[-1])\n",
        "\n",
        "# Maks grense på korte intervall for interpolering\n",
        "diff_max = 15\n",
        "\n",
        "# Lagring av antall manglende verider i korte intervaller\n",
        "res_ash_manglende_korteintervall = 0\n",
        "\n",
        "# Lager liste for start og slutt på korte intervaller med manglende verdier for NIRash\n",
        "nirash_manglende_maks15 = list()\n",
        "\n",
        "# Lager liste for start og slutt på lengre intervaller med manglende verdier for NIRash\n",
        "nirash_manglende_min15 = list()\n",
        "\n",
        "\n",
        "for i,j in zip(nirash_manglende_index_start, nirash_manglende_index_slutt):\n",
        "  nirash_mangel = prosessert_data[i:j].isnull().sum()['NIRash']\n",
        "\n",
        "# Lagrer alle start og sluttid for korte intervaller mindre enn maks tid\n",
        "  if nirash_mangel <= diff_max:\n",
        "    nirash_manglende_maks15.append((i,j))\n",
        "\n",
        "    # Summerer antall manglende verdier i de korte intertaller\n",
        "    res_water_manglende_korteintervall += nirash_mangel\n",
        "\n",
        "    # Sjekker om de korte intervaller inneholder kvalitetsmålinger\n",
        "    respons_mangel = prosessert_data[i:j].isnull().sum()[['Collagen',\n",
        "                                                          'Mw',\n",
        "                                                          'SmallMolecules',\n",
        "                                                          'BrixAdjusted']]\n",
        "    if nirash_mangel > min(respons_mangel.values):\n",
        "      print(\"Tidsintervallet {} til {} har flere manglende NIRash målinger enn kvalitetsmålinger\".format(i, j))\n",
        "      print(\"NIRash {}\".format(nirash_mangel))\n",
        "      print(respons_mangel)\n",
        "\n",
        "# Lagrer alle start og slutttid for lengre intervaller mer enn maks tid\n",
        "  else:\n",
        "    nirash_manglende_min15.append((i,j))\n",
        "\n",
        "print(res_ash_manglende_korteintervall,\n",
        "      \"av\",\n",
        "      prosessert_data.isnull().sum()['NIRash'],\n",
        "      \"NIRash målinger som mangler er i kortere intervaller enn\",\n",
        "      diff_max,\n",
        "      \"min\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMkDl1LVb_MU",
        "outputId": "cb8d32e4-2cd3-4395-fdfe-11ceeb707410"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 av 148 NIRash målinger som mangler er i kortere intervaller enn 15 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolering av resterende manglende verdier"
      ],
      "metadata": {
        "id": "l8YlCiEEeCYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOF for behandling av manglende verdier"
      ],
      "metadata": {
        "id": "6xNnTvgJiyWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for prediktor in prediktorer:\n",
        "  prosessert_data[prediktor] = prosessert_data[prediktor].fillna(method = 'ffill')"
      ],
      "metadata": {
        "id": "En9GXBaPgjlO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspeksjon av mulige ekstremverdier"
      ],
      "metadata": {
        "id": "xpv8M0zUHpSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ekstremverdi inspeksjon med HBOS"
      ],
      "metadata": {
        "id": "v2-00O35Hwnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hbos = HBOS()\n",
        "hbos.fit(X)\n",
        "\n",
        "y_predikert = hbos.labels_\n",
        "y_scores = hbos.decision_scores_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "V50HeXX5IGAs",
        "outputId": "180c23f4-247b-4513-f38c-12d8c55fb6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3294d88800e9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhbos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHBOS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhbos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_predikert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhbos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhbos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_scores_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyod/models/hbos.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# validate inputs X and y (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oppdeling av original datasett for hver kvalitetsmåling"
      ],
      "metadata": {
        "id": "F6D9oFXxN21p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHPC7AUM7EFp"
      },
      "outputs": [],
      "source": [
        "# Trekker ut prediktorer som et eget datasett\n",
        "prediktor_data = bioco_rå_data.iloc[:, :-4]\n",
        "\n",
        "# Datasett for \"Collagen\"\n",
        "collagen_datasett = pd.concat([prediktor,\n",
        "                               bioco_rå_data['Collagen']],\n",
        "                              axis=1)\n",
        "\n",
        "# Datasett for \"Mw\"\n",
        "mw_datasett = pd.concat([prediktor,\n",
        "                         bioco_rå_data['Mw']],\n",
        "                        axis=1)\n",
        "\n",
        "# Datasett for \"SmallMolecules\"\n",
        "smallmolecules_datasett = pd.concat([prediktor,\n",
        "                                     bioco_rå_data['SmallMolecules']],\n",
        "                                    axis=1)\n",
        "\n",
        "# Datasett for \"BrixAdjusted\"\n",
        "brixadjusted_datasett = pd.concat([prediktor,\n",
        "                                   bioco_rå_data['BrixAdjusted']],\n",
        "                                  axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lagrer hvert datasett som csv"
      ],
      "metadata": {
        "id": "RCkELUJ5N9Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collagen datasett som csv fil\n",
        "collagen_datasett.to_csv('')"
      ],
      "metadata": {
        "id": "K1CZmo6ZN_hi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}